{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SOA - Ejercicio 2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMvZvMUQ89auSjDmgF20r+k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marceloflores-soa/EA3-Colab/blob/main/SOA_Ejercicio_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9jnou6GqzWY"
      },
      "source": [
        "## Descripción Ejecicio 2\n",
        "El ejercicio posee dos versiones del algoritmo para la multiplicación de matrices, la primera de ellas deberá ejecutarse en el entorno CPU con el lenguaje Python y la segunda en el entorno GPU utilizando el lenguaje Cuda junto con la librería pycuda.\n",
        "\n",
        "La finalidad del ejercicio es mostrar la ejecución de un algoritmo de multiplicación de matrices para CPU y GPU.\n",
        "\n",
        "Para poder realizar esta multiplicación se realiza una validación para que esta pueda realizarse. Si tenemos una matriz A de m filas y **n columnas**, sólo la podremos multiplicar por una matriz B que tenga **n filas** y p columnas (mismo número de columnas de A, que de filas de B):\n",
        "\n",
        "![multiplicacion-2.png](data:image/png;base64,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)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSP6j2u0rdHA"
      },
      "source": [
        "\n",
        "## Instalación de PyCuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffXgFi_Frhl8",
        "outputId": "7f049233-6230-4517-9a44-510434bb3455"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 15.7MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.8)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=620900 sha256=b30f6edf5eacdb9dc7878532e8a30394da789f0c4f933287719eee19a5aaf393\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=3b0155dd2024c4bf77060196cdcac73ef42f21a715f8e6f945ddc409e2ae22ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF7jCOrRrnct"
      },
      "source": [
        "## Desarrollo CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJJaULxwdJxh",
        "outputId": "4f14c67d-5778-4b74-b847-6209e3de4d3f"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title Ingrese filas y columas de cada matriz: { vertical-output: true }\n",
        "\n",
        "matriz_A_filas =   2#@param {type: \"number\"}\n",
        "matriz_B_columnas = 2#@param {type: \"number\"}\n",
        "columnas_A_filas_B = 2#@param {type: \"number\"}\n",
        "\n",
        "if (columnas_A_filas_B <= 0 or matriz_A_filas < 0 or matriz_B_columnas < 0 ):\n",
        "  raise Exception(\"Por favor, no ingrese números negativos.\") \n",
        "\n",
        "# ---Importamos las librerías de CUDA\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# ---Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "# ---MAIN\n",
        "tiempo_total = datetime.now()\n",
        "# Generamos matrices con valores entre 0 y 100\n",
        "matriz_A = np.random.rand(matriz_A_filas, columnas_A_filas_B).astype(np.float32)\n",
        "matriz_B = np.random.rand(columnas_A_filas_B, matriz_B_columnas).astype(np.float32)\n",
        "resultado = np.zeros((matriz_A_filas,matriz_B_columnas), dtype=float)\n",
        "\n",
        "for i in range(len(matriz_A)):\n",
        "   for j in range(len(matriz_B[0])):\n",
        "       for k in range(len(matriz_B)):\n",
        "           resultado[i][j] += matriz_A[i][k] * matriz_B[k][j]\n",
        "\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "print( \"Resultados\" )\n",
        "print( \"------------------------------------\")\n",
        "print(\"Matriz A: \")\n",
        "print(np.array2string(matriz_A, precision=3, separator=',', suppress_small=True))\n",
        "print()\n",
        "print(\"Matriz B: \")\n",
        "print(np.array2string(matriz_B, precision=3, separator=',', suppress_small=True))\n",
        "print()\n",
        "print(\"Matriz Resultante: \")\n",
        "print(np.array2string(resultado, precision=3, separator=',', suppress_small=True))\n",
        "print()\n",
        "print( \"Tiempos\")\n",
        "print( \"------------------------------------\")\n",
        "# Informo tiempos\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultados\n",
            "------------------------------------\n",
            "Matriz A: \n",
            "[[0.705,0.399],\n",
            " [0.15 ,0.514]]\n",
            "\n",
            "Matriz B: \n",
            "[[0.479,0.227],\n",
            " [0.768,0.581]]\n",
            "\n",
            "Matriz Resultante: \n",
            "[[0.644,0.392],\n",
            " [0.466,0.333]]\n",
            "\n",
            "Tiempos\n",
            "------------------------------------\n",
            "Tiempo CPU:  0.224 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_tlzrcQKHac"
      },
      "source": [
        "# Dessarrollo GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BByME9ZsKrVj"
      },
      "source": [
        "* Para poder ejecutar el siguiente desarrollo, por favor, cambie el **tipo de entorno de ejecución** a GPU. Ingresando en \"Herramientas\" -> \"Tipo de entorno de ejecución\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgoQfOA3KM5X",
        "outputId": "667185de-ae29-43a4-f5a5-031a44e73368"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title Ingrese filas y columas de cada matriz: { vertical-output: true }\n",
        "\n",
        "matriz_A_filas =   2#@param {type: \"number\"}\n",
        "matriz_B_columnas = 2#@param {type: \"number\"}\n",
        "columnas_A_filas_B = 2#@param {type: \"number\"}\n",
        "\n",
        "if (columnas_A_filas_B <= 0 or matriz_A_filas < 0 or matriz_B_columnas < 0 ):\n",
        "  raise Exception(\"Por favor, no ingrese números negativos. El atributo Filas_B_Columnas_A no puede ser igual a 0\") \n",
        "\n",
        "# ---Importamos librerias PyCuda\n",
        "import numpy as np\n",
        "import time\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "from datetime import datetime\n",
        "\n",
        "# ----Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "MATRIX_SIZE = matriz_A_filas * matriz_B_columnas\n",
        "BLOCK_SIZE = 32\n",
        "\n",
        "#--- MAIN\n",
        "\n",
        "# CPU - Defino la memoria de los vectores en cpu.\n",
        "matriz_A = np.random.randn(matriz_A_filas, columnas_A_filas_B)*10\n",
        "matriz_A = matriz_A.astype(np.float32)\n",
        "\n",
        "matriz_B = np.random.randn(columnas_A_filas_B, matriz_B_columnas)*10\n",
        "matriz_B = matriz_B.astype(np.float32)\n",
        "\n",
        "resultado = np.zeros((matriz_A_filas,matriz_B_columnas), dtype=float)\n",
        "resultado = resultado.astype(np.float32)\n",
        "\n",
        "# CPU - reservo la memoria GPU\n",
        "a_gpu = cuda.mem_alloc(matriz_A.nbytes)\n",
        "b_gpu = cuda.mem_alloc(matriz_B.nbytes)\n",
        "c_gpu = cuda.mem_alloc(resultado.nbytes)\n",
        "\n",
        "# GPU - Copio la memoria al GPU\n",
        "cuda.memcpy_htod(a_gpu, matriz_A)\n",
        "cuda.memcpy_htod(b_gpu, matriz_B)\n",
        "\n",
        "module = SourceModule(\"\"\"\n",
        "\n",
        "__global__ void MatrixMulKernel(int n, float *A, float *B, float *C){\n",
        "\n",
        "  // Índice de hilos\n",
        "  int tx = threadIdx.x;\n",
        "  int ty = threadIdx.y;\n",
        "  \n",
        "  // Índice de bloques\n",
        "  int bx = blockIdx.x;\n",
        "  int by = blockIdx.y;\n",
        "\n",
        "  int row = by*blockDim.y + ty;\n",
        "  int col = bx*blockDim.x + tx;\n",
        "\n",
        "  if(row < n && col < n){\n",
        "    float val = 0.0;\n",
        "    for(int i=0; i<n; ++i){\n",
        "\n",
        "      //cada hilo carga un elemento de cada matriz\n",
        "      val += A[row*n + i]*B[n*i + col];\n",
        "      __syncthreads();\n",
        "    }\n",
        "    C[row*n + col] = val;\n",
        "  }\n",
        "}\n",
        "\n",
        "\"\"\") \n",
        "\n",
        "# Definición funcion Kernel\n",
        "kernel = module.get_function(\"MatrixMulKernel\")\n",
        "\n",
        "if MATRIX_SIZE%BLOCK_SIZE != 0:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE+1,MATRIX_SIZE//BLOCK_SIZE+1,1)\n",
        "else:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE,MATRIX_SIZE//BLOCK_SIZE,1)\n",
        "\n",
        "tiempo_gpu = datetime.now()\n",
        "# Ejecución entorno GPU\n",
        "kernel(np.int32(MATRIX_SIZE), a_gpu, b_gpu, c_gpu, block=( BLOCK_SIZE, BLOCK_SIZE, 1 ), grid=grid);\n",
        "tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "# GPU - Copio el resultado desde la memoria GPU.\n",
        "cuda.memcpy_dtoh(resultado, c_gpu)\n",
        "\n",
        "# Informo resultados\n",
        "print( \"Resultados\" )\n",
        "print( \"------------------------------------\")\n",
        "print(\"Matriz A: \")\n",
        "print(np.array2string(matriz_A, precision=3, separator=',', suppress_small=True))\n",
        "print()\n",
        "print(\"Matriz B: \")\n",
        "print(np.array2string(matriz_B, precision=3, separator=',', suppress_small=True))\n",
        "print()\n",
        "print(\"Matriz Resultante: \")\n",
        "print(np.array2string(resultado, precision=3, separator=',', suppress_small=True))\n",
        "print()\n",
        "\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "# Informo tiempos\n",
        "print( \"Tiempos\" )\n",
        "print( \"------------------------------------\")\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "print(\"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\") \n",
        "print( \"------------------------------------\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultados\n",
            "------------------------------------\n",
            "Matriz A: \n",
            "[[ 6.469, 2.886],\n",
            " [-3.035, 0.164]]\n",
            "\n",
            "Matriz B: \n",
            "[[  5.749,  0.897],\n",
            " [-16.77 , 25.109]]\n",
            "\n",
            "Matriz Resultante: \n",
            "[[  37.188,   5.805],\n",
            " [-108.476, 162.419]]\n",
            "\n",
            "Tiempos\n",
            "------------------------------------\n",
            "Tiempo CPU:  927.974 [ms]\n",
            "Tiempo GPU:  1.795 [ms]\n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz3UFj5sZMGW"
      },
      "source": [
        "## Tablas de pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oMldBXjZNaH"
      },
      "source": [
        "### *CPU\n",
        "\n",
        " Procesador | Función | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tamaño de vectores desde Colab.\n",
        "CPU      |  import                | Importa los módulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  raise Exception()     | Lanza una exception.\n",
        "CPU      |  np.random.randn(X,Y).astype(np.float32) | Inicializa los vectores **matriz_A y matriz_B** con cantidad_N de números random entre el 0 y el 1.\n",
        "CPU      |  tiempo_en_ms      | Transforma el tiempo en milisegundos.\n",
        "CPU      |  array2string      | Transforma el array en string con 3 decimales.\n",
        "CPU      |  print()               | Informo los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kq7lAW0ZP9i"
      },
      "source": [
        "### *GPU\n",
        "\n",
        " Procesador | Funciòn | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tamaño de vectores desde Colab.\n",
        "CPU      |  import                | Importa los módulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  raise Exception()     | Lanza una exception.\n",
        "CPU      |  np.random.randn(X,Y) | Inicializa los vectores matriz_A y matriz_B con números random entre el 0 y el 1.\n",
        "CPU      |  np.astype(float32)            | Defino los valores dentro de los vectores como float32.\n",
        "CPU      |  np.zeros | Genera una matriz de ceros.\n",
        "**GPU**  |  pycuda.driver.in()      | Indica que el array debe copiarse en el dispositivo de cómputo antes de invocar el kernel.\n",
        "**GPU**  |  pycuda.driver.out()    | Indica que el array debe copiarse del dispositivo de cómputo después de invocar el kernel.\n",
        "CPU      |  SourceModule()        | Define el código del kernel. \n",
        "CPU      |  module.get_function() | Genera la función del kernel GPU.\n",
        "**GPU**  |  kernel()              | Ejecuta el kernel en GPU.\n",
        "CPU      |  tiempo_en_ms()               | Transforma el tiempo en milisegundos.\n",
        "CPU      |  array2string      | Transforma el array en string con 3 decimales.\n",
        "CPU      |  print()               | Informo los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkNVEHI2ZYot"
      },
      "source": [
        "## Conclución"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7596D5UHZZ6_"
      },
      "source": [
        "Al ejecutar el algoritmo de multiplicación de matrices en **[1]** CPU  y **[2]** GPU, ingresando un valores altos para las matrices.\n",
        "**[3]** La implementación realizada con el procesador GPU da una clara ventaja utilizando su paralelismo y logra tiempos mucho más cortos para realizar el producto de matrices en los test realizados con valores grandes y ejecución de hilos 1024 (bloques de tamaño 32 x 32); **[4]** ya que cada hilo será el encargado de calcular el valor resultante en la nueva matriz, esto quiere decir que se generarán tantos hilos como posiciones posea la matriz resultante (filas de la matriz A y columnas de la matriz B).\n",
        "\n",
        "**[5]** Este ejecicio demuestra el poder que tiene GPU en el paralelismo, lo que puede aplicarse en el ambito de Data Science y Data Mining. Por ejemplo utilizando la librería Rapids. \n",
        "Por mi parte, desconocia en profundidad los beneficios del procesamiento GPU, es muy interesante aprender sobre este tema ya que me estoy oriendando hacia la rama de Data Science para el futuro. Estuve implementando en Colab algunos algoritmos en base a la libreria Pandas, utilizando algoritmos de Skylearn de Arboles de decision, KNN y Regresión lineal. Profundizare en el futuro la ejecución de algun algoritmo para GPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a3n2ZVDZbhw"
      },
      "source": [
        "## Referencias Leídas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H99nQtTbZc7r"
      },
      "source": [
        "La investigación para la resolución de los problemas la obtuve del material de clase, documentación de pycuda y diversas webs en la que se trataban ejemplos y comparaciones entre ejecuciones cpu y gpu.\n",
        "\n",
        "[1] https://www.cartagena99.com/recursos/alumnos/apuntes/introduccion%20matrices.pdf\n",
        "\n",
        "[2] https://www.tutorialspoint.com/cuda/cuda_matrix_multiplication.htm\n",
        "\n",
        "[3] http://www.ijcee.org/vol9/949-E1621.pdf\n",
        "\n",
        "[4] https://shephexd.github.io/development/2017/02/19/pycuda.html\n",
        "\n",
        "[5] https://developer.nvidia.com/rapids\n"
      ]
    }
  ]
}