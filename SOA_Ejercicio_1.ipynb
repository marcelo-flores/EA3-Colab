{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SOA - Ejercicio 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZEMTX5G3eufxEFMcv7Dir",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marceloflores-soa/EA3-Colab/blob/main/SOA_Ejercicio_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU6Cy5hdHU10"
      },
      "source": [
        "## Descripci√≥n Ejecicio 1\n",
        "El ejercicio plantea la implementaci√≥n de 2 algoritmos: Producto Escalar y Ordenamiento QuickSort. Esto fue realizado para identificar velocidades y beneficios en una operaci√≥n aritmetica con el producto escalar y un ordenamiento de vector en recursividad.\n",
        "Ambos algoritmos plantean dos versiones, la primera de ellas deber√° ejecutarse en el entorno CPU con el lenguaje Python y la segunda en el entorno GPU utilizando el lenguaje Cuda junto con la librer√≠a pycuda.\n",
        "\n",
        "La finalidad del ejercicio es mostrar la ejecuci√≥n de un producto escalar para CPU y GPU.\n",
        "\n",
        "**Producto Escalar**\n",
        "\n",
        "El producto escalar de dos vectores  ùëé‚Üí y ùëè‚Üí devuelve un escalar que se obtiene como la suma de las multiplicaciones una a una de las componentes cartesianas de los 2 vectores ùëé‚Üí y ùëè‚Üí.\n",
        "\n",
        "**QuickSort**\n",
        "\n",
        "√âste algoritmo se basa en el principio de divide y conquistar√°s. Resulta m√°s f√°cil ordenar listas peque√±as que una grande, con lo cual ir√° descomponiendo la lista en dos partes y ordenando esas partes. Para √©sto utiliza la recursividad.\n",
        "\n",
        "\n",
        "Se medir√°n los tiempos que demora la ejecuci√≥n en CPU y GPU, y se har√° foco en la utilizaci√≥n de paralelimos a partir de GPU.\n",
        "\n",
        "Para entender mejor lo mencionado, ejecutaremos las pruebas y veremos entonces las conclusiones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffgZWEC3Knyc"
      },
      "source": [
        "# Instalaci√≥n de PyCuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zA_M4bGdzEg",
        "outputId": "903bf4ab-97a7-4e56-ecb8-c400abd9c1e0"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.6MB 22.1MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz (62kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71kB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81kB 12.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.8)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=620900 sha256=cc06153fab3d26127b8cee402808744f7967f06d31ffb556e6a31cc1620de5fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=d76a558d2bb5f2d380cc18425dca89ab36df32c20b47e3e4e80e5aa4866a3001\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzXsNnIrAqPG"
      },
      "source": [
        "# PRODUCTO ESCALAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDtDcY0NKtMq"
      },
      "source": [
        "## Desarrollo - CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQQg2iDrKuVU",
        "outputId": "32a0c808-73cd-4935-a93e-1557539267af"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title Ingrese el tama√±o del vector { vertical-output: true }\n",
        "\n",
        "N = 100000#@param {type: \"number\"}\n",
        "if (N <= 0):\n",
        "  raise Exception(\"Solo se aceptan n√∫meros positivos\") \n",
        "  \n",
        "# ---Importamos las librer√≠as de CUDA\n",
        "import random\n",
        "import numpy as np \n",
        "from datetime import datetime\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "# ---Definici√≥n de funci√≥n para producto escalar \n",
        "def dot(K, L):\n",
        "   if len(K) != len(L):\n",
        "      return 0\n",
        "   return sum(i[0] * i[1] for i in zip(K, L))\n",
        "\n",
        "\n",
        "# ---Definici√≥n de funci√≥n que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "\n",
        "# Creamos valores entre 0 y 1 para producto escalar\n",
        "h_a = np.random.randn(1,N)\n",
        "h_b = np.random.randn(1, N)\n",
        "\n",
        "print(\"Vector A: \", np.array2string(h_a, precision=3, separator=',', suppress_small=True))\n",
        "print(\"\")\n",
        "print(\"Vector B: \", np.array2string(h_b, precision=3, separator=',', suppress_small=True))\n",
        "\n",
        "# Calculamos el producto escalar\n",
        "h_c = dot(h_a, h_b)\n",
        "\n",
        "\n",
        "# Mostramos los resultados por pantalla\n",
        "print(\"\")\n",
        "print(\"Producto Escalar: \", np.array2string(h_c, precision=3, separator=',', suppress_small=True),\" = \", np.sum(h_c))\n",
        "print(\"\")\n",
        "print(\"---TIEMPOS DE CPU RESULTANTES---\")\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector A:  [[-1.672, 1.92 , 2.629,...,-0.1  ,-0.5  , 1.508]]\n",
            "\n",
            "Vector B:  [[-0.367, 0.533,-0.741,...,-0.318,-0.213,-1.326]]\n",
            "\n",
            "Producto Escalar:  [ 0.614, 1.024,-1.947,..., 0.032, 0.106,-1.999]  =  -240.9154600378153\n",
            "\n",
            "---TIEMPOS DE CPU RESULTANTES---\n",
            "Tiempo CPU:  14.59 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LbVSAUHKxOd"
      },
      "source": [
        "## Desarrollo GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6sbAXZCLJNe"
      },
      "source": [
        "* Para poder ejecutar el siguiente desarrollo, por favor, cambie el **tipo de entorno de ejecuci√≥n** a GPU. Ingresando en \"Herramientas\" -> \"Tipo de entorno de ejecuci√≥n\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "MxZcy5accWGI",
        "outputId": "d5fec381-b6bc-43db-edfb-5ff08f00958d"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title Ingrese el tama√±o del vector { vertical-output: true }\n",
        "# Ingresamos el tama√±o de los vectores\n",
        "N = 100000#@param {type: \"number\"}\n",
        "\n",
        "if (N <= 0):\n",
        "  raise Exception(\"Solo se aceptan n√∫meros positivos\") \n",
        "# --------------------------------------------\n",
        "# ---Importamos las librer√≠as de CUDA\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "# ---Definici√≥n de funci√≥n que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "# ---Configuraci√≥n de ejecuci√≥n de hilos\n",
        "def iDivUp(a, b):\n",
        "    return a // b + 1\n",
        "\n",
        "# ---Main\n",
        "\n",
        "# Comenzamos a contar el tiempo de procesamiento\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "dim_hilo = 256\n",
        "\n",
        "# Creamos valores entre 0 y 1 para producto escalar\n",
        "h_a = np.random.randn(1,N)\n",
        "h_b = np.random.randn(1, N)\n",
        "\n",
        "print(\"Vector A: \", np.array2string(h_a, precision=3, separator=',', suppress_small=True))\n",
        "print(\"\")\n",
        "print(\"Vector B: \", np.array2string(h_b, precision=3, separator=',', suppress_small=True))\n",
        "\n",
        "# Defino los 3 vectores para el producto escalar\n",
        "h_a = h_a.astype(np.float32)\n",
        "h_b = h_b.astype(np.float32)\n",
        "h_c = np.empty_like(h_a)\n",
        "\n",
        "# Defino la funci√≥n kernel que ejecutar√° en GPU\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void dotProduct(float * __restrict__ d_c, const float * __restrict__ d_a, \n",
        "                                                    const float * __restrict__ d_b,\n",
        "                                                    const int N)\n",
        "{\n",
        "  const int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  if (tid >= N) return;\n",
        "  d_c[tid] = d_a[tid] * d_b[tid];\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# Defino la funci√≥n para el producto escalar\n",
        "kernel = module.get_function(\"dotProduct\")\n",
        "\n",
        "# Ejecuta el kernel\n",
        "blockDim = (dim_hilo, 1, 1)\n",
        "gridDim = (iDivUp(N, dim_hilo), 1, 1)\n",
        "\n",
        "tiempo_gpu = datetime.now()\n",
        "\n",
        "kernel(cuda.Out(h_c), cuda.In(h_a), cuda.In(h_b), np.int32(N), block = blockDim, grid = gridDim)\n",
        "\n",
        "tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "\n",
        "\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "# Mostramos los resultados por pantalla\n",
        "print(\"\")\n",
        "print(\"Producto Escalar: \", np.array2string(h_c, precision=3, separator=',', suppress_small=True),\" = \", np.sum(h_c))\n",
        "print(\"---TIEMPOS DE CPU y GPU RESULTANTES---\")\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "print(\"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\" )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4b2933a849c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoinit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSourceModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycuda'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG-j67o2Ml2D"
      },
      "source": [
        "## Tablas de pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWcFKBhpqtzy"
      },
      "source": [
        "### *CPU\n",
        "\n",
        " Procesador | Funci√≥n | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tama√±o de vectores desde Colab.\n",
        "CPU      |  import                | Importa los m√≥dulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  raise Exception()     | Lanza una exception.\n",
        "CPU      |  np.random.randn(1,N) | Inicializa los vectores **h_a y h_b** con cantidad_N de n√∫meros random entre el 0 y el 1.\n",
        "CPU      |  dot(K, L)      | Realiza el producto cartesiano.\n",
        "CPU      |  tiempo_en_ms      | Transforma el tiempo en milisegundos.\n",
        "CPU      |  print()               | Informo los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYogePv7sLYv"
      },
      "source": [
        "### *GPU\n",
        "\n",
        " Procesador | Funci√≤n | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tama√±o de vectores desde Colab.\n",
        "CPU      |  import                | Importa los m√≥dulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  raise Exception()     | Lanza una exception.\n",
        "CPU      |  np.random.randn(1,N) | Inicializa los vectores h_a y h_b con cantidad_N de n√∫meros random entre el 0 y el 1.\n",
        "CPU      |  np.astype(float32)            | Defino los valores dentro de los vectores como float32.\n",
        "CPU      |  np.empty_like( **h_a** ) | Genera un array vacio del mismo tipo que **h_a** y se lo asigna a **h_c**.\n",
        "**GPU**  |  pycuda.driver.in()      | Indica que el array debe copiarse en el dispositivo de c√≥mputo antes de invocar el kernel.\n",
        "**GPU**  |  pycuda.driver.out()    | Indica que el array debe copiarse del dispositivo de c√≥mputo despu√©s de invocar el kernel.\n",
        "CPU      |  SourceModule()        | Define el c√≥digo del kernel. \n",
        "CPU      |  module.get_function() | Genera la funci√≥n del kernel GPU.\n",
        "CPU      |  iDivUp         | Calcula las dimensiones.\n",
        "**GPU**  |  kernel()              | Ejecuta el kernel en GPU.\n",
        "CPU      |  tiempo_en_ms()               | Transforma el tiempo en milisegundos.\n",
        "CPU      |  print()               | Informo los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DAbsdYG2pL3"
      },
      "source": [
        "## Concluci√≥n sobre Producto Escalar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK09g1RW2oOR"
      },
      "source": [
        "**[1]** Ejecutamos y probamos el algoritmo de producto escalar en CPU y GPU, ingresando un valor alto para la variable N, la implementaci√≥n realizada con el procesador GPU da una clara ventaja utilizando su paralelismo y logra tiempos mucho m√°s cortos para realizar el producto escalar.\n",
        "\n",
        "Los algoritmos en GPU son eficientes cuando el problema presenta una alta intensidad aritm√©tica, que puede definirse como el n√∫mero de operaciones aritm√©ticas por dato le√≠do / escrito. En conclusi√≥n, la ejecuci√≥n en GPU demuestra un tiempo inferior en realizar operaciones matem√°ticas que procesando en CPU.\n",
        "\n",
        "**[2]** **[3]** Con el fin de buscar un algoritmo m√°s complejo a partir de la documentaci√≥n y ejemplo de PyCuda que el producto escalar, implement√© un ordenamiento del tipo QuickSort el cual utiliza un m√©todo recursivo para ordenar un vector. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX_1DgCmAxdh"
      },
      "source": [
        "# QUICKSORT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhIGTw_AA1cV"
      },
      "source": [
        "## Desarrollo - CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg-VfupNA8eV"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title Ingrese el tama√±o del vector { vertical-output: true }\n",
        "\n",
        "# ---Importamos las librer√≠as de CUDA\n",
        "import random\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "tama√±o_listado =   50#@param {type: \"number\"}\n",
        "\n",
        "if (tama√±o_listado <= 0):\n",
        "  raise Exception(\"Solo se aceptan n√∫meros positivos\") \n",
        "\n",
        "\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "# ---Funci√≥n que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "\n",
        "# ---Defino valores del listado\n",
        "arr = [random.randint(1,10) for _ in range(tama√±o_listado)]\n",
        "\n",
        "print( \"Listado original: \", arr)\n",
        "\n",
        "# ---Funci√≥n QuickSort\n",
        "def quicksort(arr):\n",
        "          if len(arr) <= 1:\n",
        "             return arr\n",
        "          pivot = arr[len(arr)//2]\n",
        "          left = [x for x in arr if x < pivot]\n",
        "          middle = [x for x in arr if x == pivot]\n",
        "          right = [x for x in arr if x > pivot]\n",
        "          return quicksort(left) + middle + quicksort(right)     \n",
        "\n",
        "# ---MAIN\n",
        "tiempo_ejecucion = datetime.now()             \n",
        "# Ejecuto ordenamiento\n",
        "resultado = quicksort(arr) \n",
        "tiempo_ejecucion = datetime.now() - tiempo_total\n",
        "# Mostramos el listado ordenado\n",
        "print( \"Listado ordenado: \", resultado )\n",
        "print( \"------------------------------------\")\n",
        "\n",
        "# Mostramos tiempos de CPU\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "print(\"Tiempo Ejecucion de Ordenamiento: \", tiempo_en_ms( tiempo_ejecucion ), \"[ms]\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4AajnIAA8ko"
      },
      "source": [
        "## Desarrollo - GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJfmN-aCLL6l"
      },
      "source": [
        "* Para poder ejecutar el siguiente desarrollo, por favor, cambie el **tipo de entorno de ejecuci√≥n** a GPU. Ingresando en \"Herramientas\" -> \"Tipo de entorno de ejecuci√≥n\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYoRPVwIA-UP"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title Ingrese el tama√±o del vector { vertical-output: true }\n",
        "\n",
        "# ---Importamos las librer√≠as de CUDA\n",
        "import random\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "from pycuda import gpuarray, compiler\n",
        "from pycuda.compiler import SourceModule\n",
        "import time\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "tama√±o_listado =   50#@param {type: \"number\"}\n",
        "\n",
        "if (tama√±o_listado <= 0):\n",
        "  raise Exception(\"Solo se aceptan n√∫meros positivos\") \n",
        "\n",
        "tiempo_total = datetime.now()\n",
        "tiempo_gpu = datetime.now()\n",
        "tiempo_gpu_final = 0\n",
        "\n",
        "\n",
        "# ---Definici√≥n de funci√≥n que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "\n",
        "# ---Definici√≥n de funci√≥n que realiza el ordenamiennto QuickSort \n",
        "def quicksort(arr):\n",
        "\n",
        "  global tiempo_gpu\n",
        "  global tiempo_gpu_final\n",
        "\n",
        "  if len(arr) <= 1:\n",
        "    return arr\n",
        " \n",
        "  else:\n",
        "\n",
        "    pivot = arr.pop()\n",
        "    pivot = np.int32(pivot)\n",
        "\n",
        "    kernel_function = \"\"\"\n",
        "    #include <stdio.h>\n",
        "                    \n",
        "    __global__ void sort(int *arr, int *arr_aux1, int *arr_aux2, int *l1_size, int *l2_size, int pivot)\n",
        "    {\n",
        "      int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "      int stride = blockDim.x * gridDim.x;            \n",
        "      for (int i = index; i < %(ARRAY_SIZE)s; i+= stride){\n",
        "        if (arr[i] < pivot)\n",
        "        {\n",
        "          arr_aux1[atomicAdd(l1_size, 1)] = arr[i];\n",
        "        }else{\n",
        "              arr_aux2[atomicAdd(l2_size, 1)] = arr[i];\n",
        "              }\n",
        "        __syncthreads();\n",
        "      }\n",
        "    }\n",
        "    \"\"\"\n",
        "    tama√±o_listado = len(arr)\n",
        "\n",
        "    # CPU - reservo la memoria GPU.\n",
        "    arr = np.asarray(arr)\n",
        "    arr = arr.astype(np.int32)\n",
        "    lista_gpu = cuda.mem_alloc(arr.nbytes)\n",
        "    lista_aux1_gpu = cuda.mem_alloc(arr.nbytes)\n",
        "    lista_aux2_gpu = cuda.mem_alloc(arr.nbytes)\n",
        "    lista_aux1_tama√±o   = cuda.mem_alloc(4)\n",
        "    lista_aux2_tama√±o   = cuda.mem_alloc(4)\n",
        "    lista_aux1_sh = np.zeros(1, dtype = np.int32)\n",
        "    lista_aux2_sh = np.zeros(1, dtype = np.int32)\n",
        "\n",
        "    # GPU - Copio la memoria al GPU.\n",
        "    cuda.memcpy_htod(lista_gpu, arr)\n",
        "    cuda.memcpy_htod(lista_aux1_tama√±o, lista_aux1_sh)\n",
        "    cuda.memcpy_htod(lista_aux2_tama√±o, lista_aux2_sh)\n",
        "\n",
        "    # GPU - Ejecuta el kernel\n",
        "    dim_hilo = 256\n",
        "    dim_bloque = np.int( (tama√±o_listado+dim_hilo-1) / dim_hilo )\n",
        "    \n",
        "    kernel_code = kernel_function % {'ARRAY_SIZE': tama√±o_listado}\n",
        "    module = compiler.SourceModule(kernel_code)\n",
        "    kernel = module.get_function(\"sort\")\n",
        "    tiempo_gpu = datetime.now()\n",
        "    kernel(lista_gpu, lista_aux1_gpu, lista_aux2_gpu, lista_aux1_tama√±o, lista_aux2_tama√±o, pivot, block=(dim_hilo, 1, 1), grid=(dim_bloque, 1))\n",
        "    tiempo_gpu = datetime.now() - tiempo_gpu \n",
        "\n",
        "    tiempo_gpu_final = tiempo_gpu_final + tiempo_gpu.total_seconds()\n",
        "\n",
        "    # GPU - Copio el resultado desde la memoria GPU.\n",
        "    cuda.memcpy_dtoh(lista_aux1_sh, lista_aux1_tama√±o)\n",
        "    cuda.memcpy_dtoh(lista_aux2_sh, lista_aux2_tama√±o)\n",
        "    arr_aux1 = np.zeros(lista_aux1_sh, dtype=np.int32)\n",
        "    arr_aux2 = np.zeros(lista_aux2_sh, dtype=np.int32)\n",
        "    cuda.memcpy_dtoh(arr_aux1, lista_aux1_gpu)\n",
        "    cuda.memcpy_dtoh(arr_aux2, lista_aux2_gpu)\n",
        "    arr_aux1 = arr_aux1.tolist()\n",
        "    arr_aux2 = arr_aux2.tolist()\n",
        "\n",
        "  return quicksort(arr_aux1) + [pivot] + quicksort(arr_aux2)\n",
        "\n",
        "# ---MAIN\n",
        "# Defino valores del listado\n",
        "arr = [random.randint(1,10) for _ in range(tama√±o_listado)]\n",
        "print( \"Listado original: \", arr)\n",
        "# Llamamos a la funcion ordenamiento \n",
        "resultado = quicksort(arr)\n",
        "print( \"Listado por quicksort: \", resultado)\n",
        "print( \"------------------------------------\")\n",
        "# Informamos los tiempos\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "print(\"Tiempo GPU: \", tiempo_gpu_final , \"[ms]\" )\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gkpae-bzA-Y7"
      },
      "source": [
        "## Tablas de pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qLN9eoxBDND"
      },
      "source": [
        "### CPU\n",
        "\n",
        " Procesador | Funci√≥n | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tama√±o de vectores desde Colab.\n",
        "CPU      |  import                | Importa los m√≥dulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  raise Exception()     | Lanza una exception.\n",
        "CPU      |  random.randint(1,10) for _ in range(cantidad_N) | Inicializa el vector **arr** con cantidad_N de n√∫meros random entre el 1 y el 10.\n",
        "CPU      |  quicksort(arr)      | Ordena el vector con recursividad.\n",
        "CPU      |  print()               | Informo los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G0O3CLyLK5k"
      },
      "source": [
        "### GPU\n",
        "\n",
        " Procesador | Funci√≤n | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tama√±o de vectores desde Colab.\n",
        "CPU      |  import                | Importa los m√≥dulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  raise Exception()     | Lanza una exception.\n",
        "CPU      |  random.randint(1,10) for _ in range(cantidad_N) | Inicializa el vector **x_cpu** con cantidad_N de n√∫meros random entre el 1 y el 10.\n",
        "CPU      |  quicksort(arr)            | Funci√≥n que ordena el vector.\n",
        "CPU      |  np.array()            | Defino los valores dentro del array **x_cpu** como int32.\n",
        "CPU      |  np.empty_like( **x_cpu** ) | Genera un array vacio del mismo tipo que **x_cpu** y se lo asigna a **r_cpu**.\n",
        "**GPU**  |  cuda.mem_alloc()      | Reserva la memoria en GPU.\n",
        "**GPU**  |  cuda.memcpy_htod()    | Copia las memorias desde el CPU al GPU.\n",
        "**GPU**  |  __syncthreads()       | Sincroniza los hilos de los distintos bloques para que puedan realizar la tarea de ordenamiento correctamente.\n",
        "CPU      |  SourceModule()        | Define el c√≥digo del kernel. \n",
        "CPU      |  module.get_function() | Genera la funci√≥n del kernel GPU.\n",
        "CPU      |  dim_tx/dim_bx         | Calcula las dimensiones.\n",
        "**GPU**  |  kernel()              | Ejecuta el kernel en GPU.\n",
        "CPU      |  cuda.memcpy_dtoh( )   | Copia el resultado desde GPU memoria A a CPU memoria R.\n",
        "CPU      |  print()               | Informo los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMK5nPaKBDhz"
      },
      "source": [
        "## Conclusi√≥n sobre QuickSort\n",
        "\n",
        "Al ejecutar el algoritmo en CPU y GPU, midiendo los tiempos sobre la ejecuci√≥n en GPU, la implementaci√≥n realizada con el procesador GPU da una clara ventaja utilizando su paralelismo y logra tiempos muy cortos. \n",
        "**[4]** Este tipo de ordenamiento muestra que hay una cantidad significativa de aceleraci√≥n en el uso de CUDA y la arquitectura Nvidia en lugar de un c√≥digo secuencial que se ejecuta en arquitecturas est√°ndar.\n",
        "\n",
        "**[5]**Sin embargo, se llega a la conclusi√≥n que este tipo de algoritmos de ordenamiento recursivo no saca todo el potencial de GPU y hay que re adaptarlos de su forma secuencial, ya que est√°n planteados para usarse secuencialmente a trav√©s de la partici√≥n del listado con un pivote. En este ejemplo, el vector que se va a clasificar se descompone pr√°cticamente en sub vectores y, mediante el enfoque de subprocesos m√∫ltiples, las GPU clasifican cada subarreglo (s) y los resultados se reducen y recopilan en el subproceso principal. El transpaso de subvectores de CPU a GPU al ser recursivo demora mucho tiempo, mucho m√°s que la ejecuci√≥n directamente de todo el algoritmo sobre CPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgL03OWVMrDn"
      },
      "source": [
        "# Referencias le√≠das\n",
        "\n",
        "La investigaci√≥n para la resoluci√≥n de los problemas la obtuve del material de clase, documentaci√≥n de pycuda y diversas webs en la que se trataban ejemplos y comparaciones entre ejecuciones cpu y gpu.\n",
        "\n",
        "[1]https://developer.download.nvidia.com/books/cuda-by-example/cuda-by-example-sample.pdf\n",
        "\n",
        "[2]https://documen.tician.de/pycuda/\n",
        "\n",
        "[3]https://wiki.tiker.net/PyCuda/\n",
        "\n",
        "[4]https://dergipark.org.tr/en/download/article-file/225714\n",
        "\n",
        "[5][a-study-of-parallel-sorting-algorithms-using-cuda-and-openmp.pdf](https://drive.google.com/file/d/1c7xBaJdbVwbmcyeHI1SW4ue0gn3oWBJx/view?usp=sharing)"
      ]
    }
  ]
}